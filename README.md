# LLM-Driven Hyperparameter Optimization для Informer

Автоматическая оптимизация гиперпараметров модели Informer с использованием LLM (Gemini).

## Ключевая идея

Проект комбинирует стандартный pipeline обучения Informer (модель для прогнозирования временных рядов) и инструментальную обвязку, которая:
- генерирует кандидатные конфигурации (архитектура + гиперпараметры) с помощью LLM;
- обучает и валидацирует каждую конфигурацию на выбранном горизонте прогноза (pred_len);
- ведёт журнал экспериментов и выбирает лучшие конфигурации.

Это упрощает поиск рабочих конфигураций без полного перебора вручную.

## Структура репозитория

Корневые файлы и папки (с кратким описанием):

- `pyproject.toml`, `uv.lock` - метаданные/лок файлы для зависимостей (используйте poetry или pip-tools по желанию).
- `optimize.py` - основной скрипт/точка входа для запуска оптимизации (CLI-обёртка, см. код).
- `train.py` - вспомогательные утилиты/скрипты для обучения модели (в корне - общие функции).
- `data/` - исходные и подготовленные CSV с датасетами (`ETTh1.csv`, `ETTh1_prepared.csv`, `ETTh2.csv` и т.д.).
- `Informer2020/` - исходная реализация Informer (код модели, загрузчики данных, эксперименты).
- `informer_checkpoints/` - директория с контрольными точками обученных моделей.
- `llm_opt_toolkit/` - набор модулей для взаимодействия с LLM и управления оптимизацией:
	- `llm_requester.py` - отправка промптов в LLM и парсинг ответов (структурированный JSON-вывод);
	- `prompt_builder.py` - генерация промптов с описанием пространства поиска и истории экспериментов;
	- `optimization_journal.py` - класс для логирования, хранения и анализа результатов (JSON-журнал);
	- `optimizator.py` - основной цикл оптимизации: запросы к LLM, тренировка кандидатов, логирование;
	- `train.py` - локальная обёртка для обучения Informer с одной конфигурацией.
- `experiments/` - записи и журналы проведённых оптимизаций (структура по датасетам и запускам).
- `results/` - результаты экспериментов (метрики, графики).
- `assets/` - графики/визуализации.
- `notebooks` - Ноутбуки с анализом экспериментов

## Схема работы
![schema](assets/schema.png)

## Результаты тестирования

### Датасет ETTH1
<details>
  <summary>Графики</summary>

#### ETTH1: Optuna vs Grid3
<img src="assets/Graphs/ETTh1_grid3.png" alt="ETTH1_pred_len_24" style="width:80%; height:auto;">

#### ETTH1: Optuna vs Grid12
<img src="assets/Graphs/ETTh1_grid12.png" alt="ETTH1_pred_len_48" style="width:80%; height:auto;">


</details>

### Датасет ETTH2
<details>
  <summary>Графики</summary>

#### ETTH2: Optuna vs Grid3
<img src="assets/Graphs/ETTh2_grid3.png" alt="ETTH1_pred_len_24" style="width:80%; height:auto;">

#### ETTH2: Optuna vs Grid12
<img src="assets/Graphs/ETTh2_grid12.png" alt="ETTH1_pred_len_48" style="width:80%; height:auto;">

</details>


## Сравнение лучших и худших гипотез

| Критерий | **Лучшие гипотезы** | **Худшие гипотезы** |
|--------|----------------|----------------|
| **Основной фокус** | Баланс **длины контекста инициализации декодера** (`label_len`) и архитектурной мощности | Влияние **глубины энкодера** и **длины входной последовательности** (`seq_len`) на качество прогноза |
| **Контекст (seq_len)** | Широкий диапазон: 48–720 ч, с акцентом на сравнение короткого и сверхдлинного контекста | Также 48–720 ч, но с сильным акцентом на **длинном контексте (720 ч)** и его сочетании с разной глубиной |
| **Роль `label_len`** | Центральный элемент: тестируются **минимальные (24–48)** и **максимальные (168–336)** значения | Менее варьируется; чаще **умеренные значения (48–168)**, используется как вспомогательный параметр |
| **Архитектурная стратегия** | Часто **полярные конфигурации**: «максимальная ширина + минимальная глубина» vs «максимальная глубина + узкая модель» | Больше **гибридных и сбалансированных** подходов (например, умеренная глубина + высокая регуляризация) |
| **Регуляризация** | Дропаут варьируется (0.05–0.2), но не всегда централен | **Агрессивная регуляризация** (dropout 0.2) часто используется при малом контексте или слабой модели |
| **Сезонность и домен** | Не упоминается явно | Явно указано: **данные с недельной сезонностью (ETTh1)** → гипотезы адаптированы под структуру данных |
| **Эффективность vs. точность** | Чёткое противопоставление: «максимальная мощность» vs «максимальная разреженность» | Акцент на **компромисс**: «может ли лёгкая модель справиться с длинным контекстом?» |
| **Декодер** | Иногда варьируется глубина (`d_layers`) | Чаще фиксированная или второстепенная роль; фокус на **энкодере** |


## Вывод
1. LLM NAS справился лучше на датасетах ETTh1 и ETTh2 при фиксированном pred_len = 24;
2. Optuna дала более лучшие результаты на датасете ETTh1 и ETTh2 при pred_len >  24;
3. Исходя из графиков при поиске с LLM NAS метрика идёт сильными скачками, и мы можем на первых итерациях найти оптимальную архитектуру;
4. Метрика при Optuna в данной задаче спускается более плавно, по сравнению с LLM NAS


## Быстрый старт

```bash
# Установка зависимостей
uv sync

# Настройка API ключа
export GEMINI_API_KEY=your_api_key_here

# Запуск оптимизации
uv run optimize --dataset data/ETTh1_prepared.csv --pred_len 24 --journal exp.json --grid_name grid3
```
### Параметры
- `dataset_path` - Путь до папки с датасетом 
- `pred_len` - Фиксированный параметр длины прогноза моделью
- `journal_name` - Название файла с базой экспериментов 
- `grid_name` - Тип сетки `GRID12` или `GRID3`. По умолчанию - `GRID12`
- `n_batches` - Количество раз когда вызываем `LLM`
- `batch_size` - Размер `json` генерируемого `LLM`. Модель генерирует `batch_size` возможных архитектур `n_batches` раз. Соответственно кол-во `trails = n_batches * batch_size`
- `temperature` - Температура для `LLM`
- `thinking_budget` - Количество токенов на `раздумье` `LLM` 


## Colab пример
[Jupyter Notebook с примером оптимизации](https://colab.research.google.com/drive/1zLzTEc_KplZxM_XAheb7YOIYxHtFXiP4?usp=sharing)

## Основные компоненты

- llm_requester.py — формирует и отправляет промпты в LLM, ожидает структурированный JSON-ответ с набором конфигураций.
- prompt_builder.py — собирает промпт: пространство поисков, ограничения (например label_len < seq_len), историю прошлых экспериментов, формат вывода.
- optimization_journal.py — хранит результаты (json), умеет возвращать историю в Markdown-таблице и искать лучший результат.
- optimizator.py — цикл: получает батч от LLM → тренирует модели → логирует результаты → обновляет историю.
- train.py — модуль, запускающий обучение Informer для одной конфигурации и возвращающий метрики (MSE/MAE).


