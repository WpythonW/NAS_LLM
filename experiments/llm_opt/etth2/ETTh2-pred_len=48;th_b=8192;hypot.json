[
  {
    "trial": 1,
    "timestamp": "2025-10-13T14:00:20.648759",
    "mae_val": 0.5751016736030579,
    "mse_val": 0.47756925225257874,
    "mae_test": 0.5144960284233093,
    "mse_test": 0.3942658603191376,
    "hypothesis": "Использование длинной входной последовательности (336) в сочетании с длинным стартовым токеном декодера (168) должно обеспечить богатый контекст, необходимый для точного прогнозирования на средний срок (48ч). Более высокое количество голов внимания (16) и умеренный фактор (5) призваны эффективно использовать этот расширенный контекст.",
    "seq_len": 336,
    "label_len": 168,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 2,
    "timestamp": "2025-10-13T14:05:37.989192",
    "mae_val": 0.5037115812301636,
    "mse_val": 0.3948136270046234,
    "mae_test": 0.41322168707847595,
    "mse_test": 0.2892206609249115,
    "hypothesis": "Данная конфигурация проверяет, достаточно ли короткой, но более релевантной недавней истории (96) при комбинировании с более глубоким кодировщиком (4 слоя) и высоким фактором внимания (10). Такой подход нацелен на эффективность при максимизации области поиска зависимостей в ограниченном окне ввода.",
    "seq_len": 96,
    "label_len": 48,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 3,
    "timestamp": "2025-10-13T14:20:13.124562",
    "mae_val": 0.7036591172218323,
    "mse_val": 0.6765484809875488,
    "mae_test": 0.6057517528533936,
    "mse_test": 0.5531262755393982,
    "hypothesis": "Тестируем пределы исторического контекста: очень длинная входная последовательность (720) и максимальная глубина кодировщика (6 слоев) могут захватить сложные долгосрочные сезонные паттерны. Используется минимальный фактор (3) для сохранения вычислительной эффективности при работе с большим объемом данных.",
    "seq_len": 720,
    "label_len": 96,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 4,
    "timestamp": "2025-10-13T14:23:41.692709",
    "mae_val": 0.4542340636253357,
    "mse_val": 0.33607980608940125,
    "mae_test": 0.4111541509628296,
    "mse_test": 0.2863132655620575,
    "hypothesis": "Исследуем, достаточно ли минимальной входной последовательности (48 часов), полагаясь на более широкий механизм внимания (16 голов) и высокий фактор (8) для интенсивной обработки наиболее недавнего прошлого. Это проверяет, важны ли только самые свежие и сфокусированные признаки для прогноза на 48 часов.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 5,
    "timestamp": "2025-10-13T14:57:00.112567",
    "mae_val": 0.4616349935531616,
    "mse_val": 0.3314839005470276,
    "mae_test": 0.4376060962677002,
    "mse_test": 0.2976527810096741,
    "hypothesis": "Использование недельного контекста (168ч) в сочетании с агрессивным механизмом внимания (16 голов, фактор 10) позволит глубоко проанализировать недельные паттерны, минуя шум долгосрочных зависимостей. Умеренная глубина кодировщика (3 слоя) призвана обеспечить баланс между репрезентативностью и вычислительной эффективностью.",
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 6,
    "timestamp": "2025-10-13T15:05:09.908001",
    "mae_val": 0.5766550898551941,
    "mse_val": 0.479805052280426,
    "mae_test": 0.5214028358459473,
    "mse_test": 0.41683152318000793,
    "hypothesis": "Проверяем, как модель справится с длинным входным окном (336ч) при использовании более глубокого кодировщика (4 слоя), но с минимизированным механизмом внимания (8 голов, фактор 3). Это позволит оценить, может ли увеличение глубины обработки компенсировать более слабый поиск зависимостей в широком контексте.",
    "seq_len": 336,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 7,
    "timestamp": "2025-10-13T15:14:18.465199",
    "mae_val": 0.4878849983215332,
    "mse_val": 0.3526158332824707,
    "mae_test": 0.5200514197349548,
    "mse_test": 0.40537169575691223,
    "hypothesis": "Мы предполагаем, что комбинация умеренно длинной входной последовательности (336) с максимальной глубиной кодировщика (6 слоев), широким вниманием (16 голов) и максимальным фактором (10) позволит модели полностью использовать расширенный исторический контекст, преодолевая ограничения ранее неудачных экспериментов с длинными последовательностями.",
    "seq_len": 336,
    "label_len": 96,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 8,
    "timestamp": "2025-10-13T15:17:19.989913",
    "mae_val": 0.336210161447525,
    "mse_val": 0.17193473875522614,
    "mae_test": 0.372749388217926,
    "mse_test": 0.22951292991638184,
    "hypothesis": "Данная конфигурация исследует эффективность короткого стартового токена декодера (24) и минимальной глубины кодировщика (2 слоя) при умеренном входном контексте (96 часов). Это нацелено на высокую вычислительную эффективность, фокусируясь на локальных зависимостях с использованием умеренного фактора внимания (5).",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 9,
    "timestamp": "2025-10-13T15:22:29.804207",
    "mae_val": 0.4908469319343567,
    "mse_val": 0.35405439138412476,
    "mae_test": 0.4302632808685303,
    "mse_test": 0.29981163144111633,
    "hypothesis": "Базируясь на успехе недельного контекста (168ч), мы увеличиваем глубину кодировщика до 4 слоев и используем агрессивный механизм внимания (16 голов, фактор 8). Сочетание этого с коротким стартовым токеном декодера (24) должно улучшить локальную фокусировку при сохранении богатой недельной информации.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 10,
    "timestamp": "2025-10-13T15:35:46.140656",
    "mae_val": 0.5060834884643555,
    "mse_val": 0.3942447602748871,
    "mae_test": 0.5575516819953918,
    "mse_test": 0.4637552499771118,
    "hypothesis": "Повторно исследуем максимальный исторический контекст (720ч), предполагая, что предыдущий провал был вызван слишком консервативным вниманием. Мы снижаем глубину кодировщика (3 слоя) для баланса и максимально увеличиваем агрессивность поиска зависимостей (16 голов, фактор 10).",
    "seq_len": 720,
    "label_len": 96,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 11,
    "timestamp": "2025-10-13T15:42:50.628381",
    "mae_val": 0.4106467664241791,
    "mse_val": 0.25404882431030273,
    "mae_test": 0.44782301783561707,
    "mse_test": 0.32144251465797424,
    "hypothesis": "Исследуем, может ли более глубокий кодировщик (4 слоя) улучшить извлечение признаков из недельного контекста (168ч), используя при этом минимальный стартовый токен (24ч) и умеренные параметры внимания (8 голов, фактор 5) для баланса между репрезентативностью и стабильностью.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 12,
    "timestamp": "2025-10-13T15:53:22.472781",
    "mae_val": 0.47541916370391846,
    "mse_val": 0.33232614398002625,
    "mae_test": 0.5194430351257324,
    "mse_test": 0.41250088810920715,
    "hypothesis": "Данная конфигурация тестирует, может ли сочетание максимального исторического контекста (720ч) и минимальной глубины кодировщика (2 слоя) с агрессивным механизмом внимания (16 голов, фактор 8) обеспечить эффективное извлечение долгосрочных сезонных паттернов, избегая избыточной сложности, наблюдавшейся ранее при 720ч.",
    "seq_len": 720,
    "label_len": 48,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 13,
    "timestamp": "2025-10-13T16:03:32.978904",
    "mae_val": 0.5072559714317322,
    "mse_val": 0.3953169286251068,
    "mae_test": 0.4765494763851166,
    "mse_test": 0.3447871506214142,
    "hypothesis": "Базируясь на предыдущих умеренных успехах с контекстом 336ч, мы максимизируем вычислительную мощность, комбинируя двухнедельный ввод с максимальной глубиной кодировщика (6 слоев) и самым агрессивным механизмом внимания (16 голов, фактор 10). Это нацелено на глубокое извлечение сложных долгосрочных зависимостей, используя умеренно короткий стартовый токен (48) для стабилизации процесса декодирования.",
    "seq_len": 336,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 14,
    "timestamp": "2025-10-13T16:06:38.760818",
    "mae_val": 0.49669235944747925,
    "mse_val": 0.38914918899536133,
    "mae_test": 0.40906503796577454,
    "mse_test": 0.287038654088974,
    "hypothesis": "Исследуем, может ли глубокий кодировщик (4 слоя) компенсировать минимальный входной контекст (48 часов), заставляя модель извлекать высокоабстрактные признаки из недавней истории. Мы используем минимальный фактор (3) для поддержания эффективности, полагаясь на глубину и максимальное количество голов (16) для сфокусированной и интенсивной обработки локальных зависимостей.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 15,
    "timestamp": "2025-10-13T16:10:57.772302",
    "mae_val": 0.45999741554260254,
    "mse_val": 0.31396424770355225,
    "mae_test": 0.4379211664199829,
    "mse_test": 0.3099793791770935,
    "hypothesis": "Мы исследуем, может ли максимальная глубина кодировщика (6 слоев) и наиболее агрессивный механизм внимания (16 голов, фактор 10) компенсировать минимальный входной контекст (48 часов), извлекая высокоабстрактные и точные признаки из самой недавней истории.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 16,
    "timestamp": "2025-10-13T16:21:04.151555",
    "mae_val": 0.7025038003921509,
    "mse_val": 0.6812767386436462,
    "mae_test": 0.6619625687599182,
    "mse_test": 0.6347854137420654,
    "hypothesis": "Проверяем эффективность использования максимального исторического контекста (720ч) при минимальной глубине кодировщика (2 слоя) и умеренных параметрах внимания (8 голов, фактор 5). Цель — избежать переобучения и вычислительной сложности, полагаясь на стабильное извлечение сезонных паттернов.",
    "seq_len": 720,
    "label_len": 96,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 17,
    "timestamp": "2025-10-13T16:27:11.951579",
    "mae_val": 0.5504379272460938,
    "mse_val": 0.4579663872718811,
    "mae_test": 0.5003657937049866,
    "mse_test": 0.3978501856327057,
    "hypothesis": "Комбинирование успешного недельного контекста (168) с максимальной глубиной кодировщика (6 слоев) и широким вниманием (16 голов) позволит модели глубоко анализировать сложные недельные паттерны. Использование умеренного стартового токена (48) и фактора (5) нацелено на стабилизацию процесса декодирования при высокой сложности кодирования.",
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 18,
    "timestamp": "2025-10-13T16:37:51.771550",
    "mae_val": 0.5560276508331299,
    "mse_val": 0.46121954917907715,
    "mae_test": 0.5857349634170532,
    "mse_test": 0.5090407729148865,
    "hypothesis": "Для исследования максимального исторического контекста (720ч), который ранее приводил к плохим результатам, мы используем минимально возможную глубину (2 слоя) и узкое внимание (8 голов) для предотвращения переобучения. При этом мы применяем максимальный фактор (10) для агрессивного поиска редких, но важных сезонных зависимостей в широком, но поверхностно обработанном окне.",
    "seq_len": 720,
    "label_len": 48,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 19,
    "timestamp": "2025-10-13T16:42:52.609383",
    "mae_val": 0.39024320244789124,
    "mse_val": 0.23141968250274658,
    "mae_test": 0.4243386387825012,
    "mse_test": 0.2785584628582001,
    "hypothesis": "Мы предполагаем, что комбинация недельного контекста (168ч) с максимальной глубиной кодировщика (6 слоев) и агрессивным механизмом внимания (16 голов, фактор 8) позволит модели извлечь максимально сложные и высокоабстрактные недельные паттерны. Использование короткого стартового токена декодера (24ч) направлено на стабилизацию процесса прогнозирования 48ч.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 20,
    "timestamp": "2025-10-13T16:48:16.269922",
    "mae_val": 0.4381914436817169,
    "mse_val": 0.29061996936798096,
    "mae_test": 0.5029680728912354,
    "mse_test": 0.4162910580635071,
    "hypothesis": "Мы исследуем, может ли модель эффективно использовать двухнедельный контекст (336ч), если применять минимальную глубину кодировщика (2 слоя) и консервативные параметры внимания (8 голов, фактор 5). Эта конфигурация нацелена на стабильность и вычислительную эффективность, пытаясь извлечь долгосрочные паттерны без риска переобучения, который наблюдался в более сложных моделях с длинным вводом.",
    "seq_len": 336,
    "label_len": 48,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 21,
    "timestamp": "2025-10-13T16:54:55.893049",
    "mae_val": 0.46262016892433167,
    "mse_val": 0.31768250465393066,
    "mae_test": 0.3989529609680176,
    "mse_test": 0.2597358524799347,
    "hypothesis": "Building on the success of moderate context (96ч) and short decoding token (24ч), мы проверим эффект максимальной сложности модели: глубокий кодировщик (6 слоев) в сочетании с агрессивным механизмом внимания (16 голов, фактор 10). This aims to intensively process the moderate input window, potentially finding higher-order dependencies missed by simpler configurations.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 22,
    "timestamp": "2025-10-13T17:03:43.412397",
    "mae_val": 0.5168627500534058,
    "mse_val": 0.39235907793045044,
    "mae_test": 0.550795316696167,
    "mse_test": 0.43607911467552185,
    "hypothesis": "Мы снова исследуем потенциал максимального исторического контекста (720ч). В отличие от предыдущих неудачных попыток, мы используем умеренную глубину кодировщика (3 слоя) и умеренный фактор (5) для стабилизации обучения, компенсируя это максимальной шириной внимания (16 голов) и относительно коротким стартовым токеном (48ч). Это позволит модели избирательно извлекать долгосрочные сезонные паттерны без избыточного усложнения.",
    "seq_len": 720,
    "label_len": 48,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 23,
    "timestamp": "2025-10-13T17:10:34.902680",
    "mae_val": 0.4008578062057495,
    "mse_val": 0.2493283748626709,
    "mae_test": 0.42023327946662903,
    "mse_test": 0.28782543540000916,
    "hypothesis": "Мы комбинируем успешный недельный контекст (168ч) и короткий стартовый токен (24ч) с максимальной глубиной кодировщика (6 слоев). Использование минимального фактора (3) и 8 голов позволит проверить, может ли увеличение глубины обработки компенсировать более узкий поиск зависимостей, обеспечивая высокую вычислительную эффективность.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 24,
    "timestamp": "2025-10-13T17:15:24.467057",
    "mae_val": 0.4389704167842865,
    "mse_val": 0.29209885001182556,
    "mae_test": 0.4492657482624054,
    "mse_test": 0.30259832739830017,
    "hypothesis": "Мы используем двухнедельный контекст (336ч) в сочетании с доказавшим свою эффективность коротким стартовым токеном (24ч) для прогноза на 48ч. Умеренная глубина (3 слоя) и умеренный фактор (5) в сочетании с широким вниманием (16 голов) нацелены на стабильное извлечение долгосрочных паттернов, избегая переобучения, наблюдавшегося при более сложных моделях с длинным вводом.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 25,
    "timestamp": "2025-10-13T17:23:51.541622",
    "mae_val": 0.4130977690219879,
    "mse_val": 0.27392637729644775,
    "mae_test": 0.45231005549430847,
    "mse_test": 0.33004030585289,
    "hypothesis": "Мы исследуем, может ли двухнедельный контекст (336ч), обработанный глубоким кодировщиком (4 слоя) с агрессивным вниманием (16 голов, фактор 8), обеспечить лучшее извлечение долгосрочных признаков, чем недельный контекст, при сохранении стабилизирующего короткого стартового токена (24ч).",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 26,
    "timestamp": "2025-10-13T17:27:50.735010",
    "mae_val": 0.4892200529575348,
    "mse_val": 0.36458638310432434,
    "mae_test": 0.4013974070549011,
    "mse_test": 0.25725290179252625,
    "hypothesis": "Мы проверяем, может ли максимальная глубина кодировщика (6 слоев) компенсировать минимальный входной контекст (48ч), используя более консервативный и эффективный механизм внимания (8 голов, фактор 5) для интенсивного извлечения признаков только из самой недавней истории.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 27,
    "timestamp": "2025-10-13T19:39:19.715225",
    "mae_val": 0.49289390444755554,
    "mse_val": 0.34150075912475586,
    "mae_test": 0.4692583382129669,
    "mse_test": 0.338862806558609,
    "hypothesis": "Мы проверяем, может ли комбинация двухнедельного контекста (336ч) с максимальной глубиной кодировщика (6 слоев) эффективно извлекать сложные долгосрочные зависимости. Использование короткого стартового токена (24ч) и умеренного механизма внимания (8 голов, фактор 5) нацелено на стабилизацию процесса декодирования, предотвращая переобучение, характерное для очень длинных последовательностей.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 28,
    "timestamp": "2025-10-13T19:41:42.965638",
    "mae_val": 0.5530285239219666,
    "mse_val": 0.4340038299560547,
    "mae_test": 0.40196099877357483,
    "mse_test": 0.2631409466266632,
    "hypothesis": "Мы проверяем эффективность минимального входного контекста (48ч) в сочетании с минимальной глубиной кодировщика (2 слоя) для максимальной вычислительной скорости. Компенсация за счет самой агрессивной конфигурации внимания (16 голов, фактор 10) нацелена на интенсивное извлечение высокорелевантных, но локальных, краткосрочных зависимостей.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 29,
    "timestamp": "2025-10-13T19:48:05.818334",
    "mae_val": 0.46857619285583496,
    "mse_val": 0.33751964569091797,
    "mae_test": 0.39080294966697693,
    "mse_test": 0.2625168561935425,
    "hypothesis": "Мы проверим, может ли максимизация глубины кодировщика (6 слоев) улучшить лучший результат, полученный на умеренном контексте (96ч) и коротком стартовом токене (24ч). Использование умеренных параметров внимания (8 голов, фактор 5) нацелено на извлечение сложных, но стабильных признаков из наиболее релевантного исторического окна.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 30,
    "timestamp": "2025-10-13T19:54:53.431312",
    "mae_val": 0.39785251021385193,
    "mse_val": 0.252553254365921,
    "mae_test": 0.44701245427131653,
    "mse_test": 0.3094681203365326,
    "hypothesis": "Исследуем эффективность двухнедельного контекста (336ч) при минимальной глубине кодировщика (2 слоя) и самой агрессивной конфигурации внимания (16 голов, фактор 10). Этот подход нацелен на широкое и интенсивное сканирование долгосрочных зависимостей, полагаясь на breadth of attention, а не на глубокую абстракцию признаков.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 31,
    "timestamp": "2025-10-13T19:59:06.360448",
    "mae_val": 0.5060068964958191,
    "mse_val": 0.38403433561325073,
    "mae_test": 0.43336397409439087,
    "mse_test": 0.31561437249183655,
    "hypothesis": "We hypothesize that increasing the encoder depth to 4 layers and using a maximal factor (10) within the minimal input sequence (48ч) will force the model to deeply extract high-order, short-term features, compensating for the limited context while maintaining computational stability via 8 heads.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 32,
    "timestamp": "2025-10-13T20:04:51.517542",
    "mae_val": 0.5209463238716125,
    "mse_val": 0.39247602224349976,
    "mae_test": 0.5480058789253235,
    "mse_test": 0.4342006742954254,
    "hypothesis": "Мы тестируем, может ли максимальная глубина кодировщика (6 слоев) эффективно обработать двухнедельную историю (336ч), используя при этом самый консервативный механизм внимания (8 голов, фактор 3). Это нацелено на извлечение высокоабстрактных долгосрочных признаков, минимизируя вычислительные затраты и риск переобучения в механизме внимания.",
    "seq_len": 336,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 33,
    "timestamp": "2025-10-13T20:10:14.155273",
    "mae_val": 0.4153836965560913,
    "mse_val": 0.2656927704811096,
    "mae_test": 0.3984197676181793,
    "mse_test": 0.2572258412837982,
    "hypothesis": "Мы предполагаем, что комбинация высокоэффективного умеренного контекста (96ч) и короткого стартового токена (24ч) с повышенной глубиной кодировщика (4 слоя) и агрессивным механизмом внимания (16 голов, фактор 8) позволит извлечь более сложные локальные зависимости, улучшая лучший результат, полученный на минимальной глубине.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 34,
    "timestamp": "2025-10-13T20:15:05.107477",
    "mae_val": 0.48280251026153564,
    "mse_val": 0.35232120752334595,
    "mae_test": 0.5881416201591492,
    "mse_test": 0.4919813871383667,
    "hypothesis": "Данная конфигурация исследует, может ли умеренно глубокий кодировщик (4 слоя) эффективно обрабатывать двухнедельный контекст (336ч), используя при этом минимально возможный фактор внимания (3) и узкое внимание (8 голов). Этот подход нацелен на стабильное извлечение долгосрочных признаков, отдавая приоритет глубокой абстракции над широким поиском зависимостей, что должно повысить стабильность длинной последовательности.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 35,
    "timestamp": "2025-10-13T20:20:02.552118",
    "mae_val": 0.5866445899009705,
    "mse_val": 0.49586057662963867,
    "mae_test": 0.4726165235042572,
    "mse_test": 0.345622181892395,
    "hypothesis": "Использование недельного контекста (168ч) в сочетании с умеренно длинным стартовым токеном (48ч) и глубоким кодировщиком (4 слоя) нацелено на стабильное извлечение сложных недельных паттернов. Минимальный фактор внимания (3) и 8 голов призваны сохранить вычислительную эффективность и избежать переобучения при высокой сложности модели.",
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 3
  }
]