[
  {
    "trial": 1,
    "timestamp": "2025-10-13T10:32:24.154361",
    "mae_val": 0.3622342348098755,
    "mse_val": 0.20222198963165283,
    "mae_test": 0.33797845244407654,
    "mse_test": 0.2028580605983734,
    "hypothesis": "Использование умеренного окна ретроспективы (96ч) и достаточной инициализации декодера (48ч) призвано обеспечить стабильность. Повышенная сложность модели (3 слоя, 16 голов) и средний фактор (5) должны эффективно уловить нелинейные зависимости.",
    "seq_len": 96,
    "label_len": 48,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 2,
    "timestamp": "2025-10-13T10:41:22.338736",
    "mae_val": 0.3875107765197754,
    "mse_val": 0.2322234809398651,
    "mae_test": 0.38066333532333374,
    "mse_test": 0.23248842358589172,
    "hypothesis": "Длинная входная последовательность (336ч) позволяет модели использовать сильную недельную сезонность данных ETTh. Мы используем минимальное количество слоев (2) и голов (8) для снижения переобучения, компенсируя это максимальным фактором (10) для эффективного отбора релевантных зависимостей.",
    "seq_len": 336,
    "label_len": 168,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 3,
    "timestamp": "2025-10-13T10:46:10.247907",
    "mae_val": 0.2897019684314728,
    "mse_val": 0.13125859200954437,
    "mae_test": 0.30314207077026367,
    "mse_test": 0.1598052978515625,
    "hypothesis": "Поскольку предсказательный горизонт короткий (24ч), мы проверяем, достаточно ли минимального контекста (seq_len=48) для извлечения паттернов. Чтобы компенсировать короткий вход, мы используем максимальную глубину (6 слоев, 16 голов) для повышения мощности модели, а низкий фактор (3) обеспечит быструю и точную фокусировку.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 4,
    "timestamp": "2025-10-13T11:05:15.200928",
    "mae_val": 0.5865185856819153,
    "mse_val": 0.5057755708694458,
    "mae_test": 0.5348610877990723,
    "mse_test": 0.44919803738594055,
    "hypothesis": "Используя очень длинную последовательность (720ч), мы пытаемся явно захватить месячную и сильную недельную сезонность. Мы увеличиваем глубину модели до 4 слоев по сравнению с предыдущими неудачными попытками для длинного контекста, используя при этом средний фактор (8) для эффективного просеивания обширных входных данных.",
    "seq_len": 720,
    "label_len": 336,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 8
  },
  {
    "trial": 5,
    "timestamp": "2025-10-13T11:09:47.749073",
    "mae_val": 0.4844317138195038,
    "mse_val": 0.3421526849269867,
    "mae_test": 0.4251873791217804,
    "mse_test": 0.2790446877479553,
    "hypothesis": "Эта конфигурация использует недельный контекст (168ч) для захвата сильных сезонных паттернов ETTh. Мы применяем умеренную глубину (4 слоя) и высокое количество голов (16) в сочетании с высоким фактором (8), чтобы эффективно обрабатывать и отбирать релевантные зависимости по широкому входному окну.",
    "seq_len": 168,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 6,
    "timestamp": "2025-10-13T11:12:17.839878",
    "mae_val": 0.2953200936317444,
    "mse_val": 0.13469044864177704,
    "mae_test": 0.3091264069080353,
    "mse_test": 0.16973967850208282,
    "hypothesis": "Мы проверяем эффективность успешного короткого контекста (48ч) с минимальной сложностью модели (2 слоя, 8 голов). Увеличение фактора до 5 должно обеспечить более широкий, но быстрый поиск зависимостей, проверяя, можно ли добиться высокой эффективности при значительно меньших вычислительных затратах.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 7,
    "timestamp": "2025-10-13T11:17:31.196357",
    "mae_val": 0.37402617931365967,
    "mse_val": 0.22217214107513428,
    "mae_test": 0.3411464989185333,
    "mse_test": 0.19759854674339294,
    "hypothesis": "Мы проверим умеренный контекст (96ч) с максимальной мощностью модели (6 слоев, 16 голов), чтобы убедиться, что длина свыше 48ч входной последовательности действительно не дает преимуществ. Используем низкий фактор (3) для более сфокусированного отбора зависимостей, что было эффективно для короткого контекста.",
    "seq_len": 96,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 8,
    "timestamp": "2025-10-13T11:22:12.835885",
    "mae_val": 0.317231148481369,
    "mse_val": 0.16277676820755005,
    "mae_test": 0.368687242269516,
    "mse_test": 0.22378475964069366,
    "hypothesis": "Исследуем эффективность недельного контекста (168ч) при использовании минимальной сложности модели (2 слоя, 8 голов) для предотвращения переобучения на длинной последовательности. Мы используем максимальный фактор (10), чтобы обеспечить агрессивный поиск наиболее значимых зависимостей в широком временном окне.",
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 9,
    "timestamp": "2025-10-13T11:26:05.957148",
    "mae_val": 0.3110279440879822,
    "mse_val": 0.15676936507225037,
    "mae_test": 0.2956361770629883,
    "mse_test": 0.1563359647989273,
    "hypothesis": "Мы исследуем эффективность средней сложности модели (3 слоя, 16 голов) на успешно работающем коротком контексте (48ч). Использование высокого фактора (8) призвано обеспечить агрессивный отбор зависимостей, чтобы проверить, может ли модель добиться высокой точности при более быстром расчете, чем с 6 слоями.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 8
  },
  {
    "trial": 10,
    "timestamp": "2025-10-13T11:30:02.715333",
    "mae_val": 0.32139599323272705,
    "mse_val": 0.16189977526664734,
    "mae_test": 0.359793096780777,
    "mse_test": 0.2084299474954605,
    "hypothesis": "Проверяем эффективность среднего контекста (96ч) в сочетании с минимальной инициализацией декодера (label_len=24) и повышенной глубиной кодировщика (4 слоя). Максимальный фактор (10) используется для агрессивного извлечения наиболее релевантных паттернов из 96-часового окна, что может предотвратить зашумление информации, наблюдаемое с длинными последовательностями.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 11,
    "timestamp": "2025-10-13T11:34:33.992747",
    "mae_val": 0.304256409406662,
    "mse_val": 0.15372078120708466,
    "mae_test": 0.2955956757068634,
    "mse_test": 0.1686428189277649,
    "hypothesis": "Мы комбинируем оптимальный короткий контекст (48ч) с умеренной глубиной модели (4 слоя) и максимальным количеством голов (16). Использование среднего фактора (5) должно обеспечить более эффективный отбор релевантных зависимостей, чем минимальный фактор (3), без избыточной сложности, связанной с 6 слоями.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 12,
    "timestamp": "2025-10-13T11:38:29.878766",
    "mae_val": 0.3997412621974945,
    "mse_val": 0.2428169697523117,
    "mae_test": 0.39164334535598755,
    "mse_test": 0.24740485846996307,
    "hypothesis": "Мы исследуем, может ли удвоение контекста до 96ч улучшить предсказания, если компенсировать это максимальной сложностью модели (6 слоев, 16 голов) и минимальным фактором (3). Это позволит агрессивно извлечь паттерны из расширенного окна, используя при этом минимальный токен инициализации декодера (24ч).",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 13,
    "timestamp": "2025-10-13T11:42:55.990117",
    "mae_val": 0.323059618473053,
    "mse_val": 0.1752937138080597,
    "mae_test": 0.30742594599723816,
    "mse_test": 0.1693999469280243,
    "hypothesis": "Опираясь на успешность короткого контекста (48ч), мы тестируем конфигурацию средней глубины (4 слоя) с минимальным количеством голов (8) и низким фактором (3). Это проверяет, может ли сфокусированное внимание на коротком контексте обеспечить высокую точность при сниженных вычислительных затратах по сравнению с моделями, использующими 16 голов.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 14,
    "timestamp": "2025-10-13T11:46:17.786498",
    "mae_val": 0.30630865693092346,
    "mse_val": 0.15015065670013428,
    "mae_test": 0.3366925120353699,
    "mse_test": 0.20521514117717743,
    "hypothesis": "Мы исследуем эффективность умеренного контекста (96ч) с минимальной сложностью модели (2 слоя, 8 голов) для предотвращения зашумления длинной последовательности. Средний фактор (8) должен агрессивно отфильтровать наиболее релевантные зависимости, пытаясь улучшить результат, полученный ранее при 4 слоях и факторе 10 на этом же контексте.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 8
  },
  {
    "trial": 15,
    "timestamp": "2025-10-13T11:50:38.485129",
    "mae_val": 0.34573498368263245,
    "mse_val": 0.19271287322044373,
    "mae_test": 0.31537926197052,
    "mse_test": 0.17996495962142944,
    "hypothesis": "Мы нацелены на поиск оптимального баланса для 96-часового контекста, используя умеренную глубину (3 слоя) в сочетании с высокой шириной (16 голов). Максимизация фактора (10) должна агрессивно выделить критические долгосрочные зависимости, пытаясь превзойти предыдущие результаты, полученные с более простыми 96h моделями.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 16,
    "timestamp": "2025-10-13T11:53:08.310686",
    "mae_val": 0.25321927666664124,
    "mse_val": 0.10206299275159836,
    "mae_test": 0.2703036963939667,
    "mse_test": 0.14314480125904083,
    "hypothesis": "Опираясь на успешность минимального контекста (48ч), мы тестируем низкоглубинную (2 слоя) архитектуру с максимальной шириной (16 голов), чтобы повысить способность к извлечению признаков при минимальной последовательной обработке. Использование низкого фактора (3) обеспечит сфокусированное внимание для максимальной производительности при сниженных вычислительных затратах.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 17,
    "timestamp": "2025-10-13T11:56:20.594481",
    "mae_val": 0.3081636130809784,
    "mse_val": 0.14765797555446625,
    "mae_test": 0.2863040864467621,
    "mse_test": 0.14684495329856873,
    "hypothesis": "Building on the success of the 48-hour context, this configuration tests a balanced, medium-complexity model (3 layers, 8 heads) to minimize computational overhead while retaining predictive power. Using a moderate factor (5) aims to effectively filter dependencies, seeking to improve upon the efficiency of the successful low-complexity models (2 layers, 8 heads, factor 5).",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 18,
    "timestamp": "2025-10-13T12:02:58.139123",
    "mae_val": 0.32002031803131104,
    "mse_val": 0.1574500948190689,
    "mae_test": 0.35075241327285767,
    "mse_test": 0.20998552441596985,
    "hypothesis": "This configuration attempts to leverage the full weekly seasonality (168h context) by maximizing model capacity (6 layers, 16 heads) to effectively process the extensive input. We use the minimal decoder initialization (24h) combined with a moderate factor (5) to ensure a focused yet robust feature extraction, aiming to overcome the previous suboptimal performance of long sequence models.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 19,
    "timestamp": "2025-10-13T12:06:05.427083",
    "mae_val": 0.36243298649787903,
    "mse_val": 0.20129473507404327,
    "mae_test": 0.34737256169319153,
    "mse_test": 0.20276515185832977,
    "hypothesis": "Мы используем оптимальный короткий контекст (48ч) с умеренной глубиной (4 слоя) и минимальной шириной (8 голов), чтобы найти баланс между мощностью модели и предотвращением переобучения. Средний фактор (5) обеспечит более широкий поиск зависимостей по сравнению с успешным фактором 3, тестируя устойчивость модели к немного менее сфокусированному вниманию.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 5
  },
  {
    "trial": 20,
    "timestamp": "2025-10-13T12:09:51.704107",
    "mae_val": 0.36116689443588257,
    "mse_val": 0.20858241617679596,
    "mae_test": 0.32392194867134094,
    "mse_test": 0.17941927909851074,
    "hypothesis": "Мы исследуем, может ли умеренный контекст (96ч) работать лучше при использовании минимальной сложности модели (2 слоя, 8 голов), чтобы избежать переобучения на расширенном входе. Использование длинной инициализации декодера (48ч) вместе с максимальным фактором (10) призвано агрессивно выделить наиболее важные зависимости для 24-часового прогноза.",
    "seq_len": 96,
    "label_len": 48,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 21,
    "timestamp": "2025-10-13T12:15:45.470208",
    "mae_val": 0.3245983123779297,
    "mse_val": 0.17040671408176422,
    "mae_test": 0.31258419156074524,
    "mse_test": 0.1641889065504074,
    "hypothesis": "Мы тестируем, может ли максимальный фактор (10) дополнительно улучшить производительность на оптимальном коротком контексте (48ч). Используя максимальную глубину (6 слоев) и ширину (16 голов), мы заставляем высокомощную модель агрессивно отбирать наиболее релевантные признаки для прогноза.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 22,
    "timestamp": "2025-10-13T12:18:24.508788",
    "mae_val": 0.3180409371852875,
    "mse_val": 0.15324999392032623,
    "mae_test": 0.3392612934112549,
    "mse_test": 0.18377794325351715,
    "hypothesis": "Мы исследуем эффективность недельного контекста (168ч) при использовании минимальной сложности модели (2 слоя, 8 голов) для предотвращения переобучения на длинной последовательности. Применение минимального фактора (3) должно обеспечить сфокусированное внимание для точного извлечения еженедельных паттернов.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 23,
    "timestamp": "2025-10-13T12:22:52.651618",
    "mae_val": 0.26238611340522766,
    "mse_val": 0.11118379980325699,
    "mae_test": 0.28485551476478577,
    "mse_test": 0.14814642071723938,
    "hypothesis": "Building on the superior performance of the short 48-hour context and focused attention (factor=3), we increase the encoder depth to 4 layers while maintaining maximal width (16 heads). This aims to improve feature extraction capability compared to the 2-layer optimum, seeking a robust balance between depth and computational focus for the short prediction horizon.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 24,
    "timestamp": "2025-10-13T12:27:40.875726",
    "mae_val": 0.3414212167263031,
    "mse_val": 0.17985022068023682,
    "mae_test": 0.36636587977409363,
    "mse_test": 0.21790289878845215,
    "hypothesis": "We attempt to utilize the weekly seasonality (168h context) by employing a high-capacity model (4 layers, 16 heads) coupled with the maximum factor (10). This strategy aims to aggressively filter and focus attention on the most critical dependencies within the extended input window, minimizing noise and leveraging potential weekly patterns for the 24-hour prediction.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 10
  },
  {
    "trial": 25,
    "timestamp": "2025-10-13T12:30:53.312409",
    "mae_val": 0.273661732673645,
    "mse_val": 0.12060806155204773,
    "mae_test": 0.27714139223098755,
    "mse_test": 0.13881121575832367,
    "hypothesis": "Продолжая эксплуатировать успешную стратегию минимального контекста (48ч) с максимальной шириной (16 голов) и минимальной глубиной (2 слоя), мы увеличиваем фактор внимания до 5. Это позволит модели проводить немного более широкий поиск зависимостей, тестируя, может ли более агрессивный, но быстрый отбор признаков улучшить обобщение по сравнению с максимально сфокусированным фактором 3.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 26,
    "timestamp": "2025-10-13T12:35:41.702762",
    "mae_val": 0.3136696517467499,
    "mse_val": 0.1519833356142044,
    "mae_test": 0.3577145040035248,
    "mse_test": 0.20490361750125885,
    "hypothesis": "Мы исследуем, может ли включение двух недель истории (336ч) улучшить предсказание, если компенсировать длинный вход высокой мощностью модели (4 слоя, 16 голов) и использовать минимальный, но эффективный фактор внимания (3). Это позволит высокомощной модели сфокусированно извлечь долгосрочные, вероятно, двухнедельные паттерны, избегая шума, связанного с большими факторами.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 27,
    "timestamp": "2025-10-13T12:38:53.585928",
    "mae_val": 0.2876138985157013,
    "mse_val": 0.13637158274650574,
    "mae_test": 0.3252416253089905,
    "mse_test": 0.1913963407278061,
    "hypothesis": "Мы исследуем минимально возможную сложность модели (2 слоя, 8 голов) на оптимальном коротком контексте (48ч). Использование минимального фактора (3) обеспечит сфокусированное извлечение признаков, проверяя, можно ли достичь эффективности топовых моделей при значительно сниженных вычислительных затратах.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 28,
    "timestamp": "2025-10-13T12:44:48.728332",
    "mae_val": 0.5713346600532532,
    "mse_val": 0.5186432600021362,
    "mae_test": 0.41797900199890137,
    "mse_test": 0.293958842754364,
    "hypothesis": "Мы исследуем эффективность недельного контекста (168ч) в сочетании с максимальной инициализацией декодера (label_len=96) для стабилизации прогноза. Максимальная сложность модели (6 слоев, 16 голов) и минимальный фактор (3) призваны обеспечить высокоточное и сфокусированное извлечение недельных паттернов, избегая при этом общего шума, характерного для длинных последовательностей.",
    "seq_len": 168,
    "label_len": 96,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 29,
    "timestamp": "2025-10-13T12:48:37.637522",
    "mae_val": 0.2951478660106659,
    "mse_val": 0.145990788936615,
    "mae_test": 0.29502302408218384,
    "mse_test": 0.160482719540596,
    "hypothesis": "Leveraging the optimal short context (48ч) with highly focused attention (factor 3). We use intermediate depth (3 слоев) and minimal width (8 голов) to find a sweet spot between model complexity and computational efficiency, aiming to improve generalization over the minimal 2-layer model.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 30,
    "timestamp": "2025-10-13T12:55:43.071599",
    "mae_val": 0.3021198809146881,
    "mse_val": 0.1423613578081131,
    "mae_test": 0.35884833335876465,
    "mse_test": 0.205482617020607,
    "hypothesis": "By utilizing a two-week history (336ч), we aim to capture strong long-term seasonalities. We maximize model depth and width (6 слоев, 16 голов) for maximum representation power, combined with a moderate factor (5) to ensure aggressive yet slightly broader dependency selection across the extensive input sequence.",
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 31,
    "timestamp": "2025-10-13T12:58:48.527209",
    "mae_val": 0.3062804341316223,
    "mse_val": 0.1443234086036682,
    "mae_test": 0.32612207531929016,
    "mse_test": 0.1771920621395111,
    "hypothesis": "Мы исследуем, может ли средний контекст (96ч) обеспечить высокую точность при минимальной сложности модели (2 слоя, 8 голов). Максимальный фактор (10) должен агрессивно извлечь критические паттерны из расширенного окна, компенсируя низкую вычислительную мощность.",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 10
  },
  {
    "trial": 32,
    "timestamp": "2025-10-13T13:09:59.658916",
    "mae_val": 0.42606037855148315,
    "mse_val": 0.26995351910591125,
    "mae_test": 0.4447898864746094,
    "mse_test": 0.3096579909324646,
    "hypothesis": "Мы проверяем, может ли максимальная сложность модели (6 слоев, 16 голов) в сочетании с агрессивно сфокусированным вниманием (фактор 3) успешно извлечь долгосрочные паттерны (720ч), избегая шума, который привел к провалу предыдущих экспериментов с длинным контекстом.",
    "seq_len": 720,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 33,
    "timestamp": "2025-10-13T13:25:14.571647",
    "mae_val": 0.31661808490753174,
    "mse_val": 0.16255974769592285,
    "mae_test": 0.2991168200969696,
    "mse_test": 0.16546964645385742,
    "hypothesis": "Мы используем максимальную глубину (6 слоев) на оптимальном коротком контексте (48ч). Сочетание минимальной ширины (8 голов) с максимальной фокусировкой (фактор 3) проверяет, может ли сфокусированная вертикальная обработка компенсировать горизонтальное уменьшение количества голов, снизив при этом вычислительные затраты.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3
  },
  {
    "trial": 34,
    "timestamp": "2025-10-13T13:29:06.156770",
    "mae_val": 0.3490484356880188,
    "mse_val": 0.1862865835428238,
    "mae_test": 0.3283470869064331,
    "mse_test": 0.1781332790851593,
    "hypothesis": "Мы исследуем потенциал среднего контекста (96ч) с помощью высокомощной модели (4 слоя, 16 голов). Используя умеренный фактор (5), мы стремимся добиться баланса между агрессивным отбором признаков и сохранением ключевых зависимостей в расширенном окне, что может быть более эффективным, чем избыточная фокусировка (factor 3) или излишне широкий поиск (factor 10).",
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 5
  },
  {
    "trial": 35,
    "timestamp": "2025-10-13T13:32:59.853200",
    "mae_val": 0.28768035769462585,
    "mse_val": 0.13445046544075012,
    "mae_test": 0.3136287331581116,
    "mse_test": 0.18213005363941193,
    "hypothesis": "Мы комбинируем успешные короткие параметры контекста (48ч, 16 голов, фактор 3) с промежуточной глубиной кодировщика (3 слоя). Это должно улучшить возможности абстрагирования признаков по сравнению с 2-слойным оптимумом, сохраняя при этом сфокусированное внимание и высокую параллелизацию.",
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 16,
    "factor": 3
  },
  {
    "trial": 36,
    "timestamp": "2025-10-13T13:36:43.273394",
    "mae_val": 0.3369702398777008,
    "mse_val": 0.1732192188501358,
    "mae_test": 0.34003373980522156,
    "mse_test": 0.19498316943645477,
    "hypothesis": "Мы исследуем эффективность недельного контекста (168ч) с минимальной глубиной (2 слоя) и максимальной шириной (16 голов). Использование максимального фактора (10) призвано агрессивно отфильтровать обширный вход, фокусируясь только на наиболее критичных долгосрочных зависимостях и предотвращая переобучение.",
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 10
  }
]