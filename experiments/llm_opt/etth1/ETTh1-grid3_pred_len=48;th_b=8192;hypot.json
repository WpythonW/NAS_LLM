[
  {
    "trial": 1,
    "timestamp": "2025-11-05T11:33:07.164456",
    "mae_val": 0.593321681022644,
    "mse_val": 0.48554590344429016,
    "mae_test": 0.3113018274307251,
    "mse_test": 0.1602519452571869,
    "seq_len": 96,
    "label_len": 48,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 5,
    "d_model": 512,
    "d_ff": 2048,
    "d_layers": 1,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация использует умеренную длину входной последовательности (96 часов) и стандартный размер модели (d_model=512) для эффективного захвата краткосрочных и среднесрочных часовых зависимостей в наборе данных ETTh, балансируя вычислительную стоимость и репрезентативную мощность."
  },
  {
    "trial": 2,
    "timestamp": "2025-11-05T12:22:58.268227",
    "mae_val": 0.39159128069877625,
    "mse_val": 0.23225148022174835,
    "mae_test": 0.4131397008895874,
    "mse_test": 0.24601586163043976,
    "seq_len": 720,
    "label_len": 336,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 10,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 3,
    "dropout": 0.2,
    "hypothesis": "Используя максимальную длину последовательности (720) и наибольшие размеры модели (768, 3072), эта конфигурация направлена на тщательное исследование сложных, долгосрочных временных паттернов (приближение месячных циклов) в данных ETTh, применяя более высокий dropout для предотвращения переобучения."
  },
  {
    "trial": 3,
    "timestamp": "2025-11-05T12:23:37.504013",
    "mae_val": 0.6211346387863159,
    "mse_val": 0.48419538140296936,
    "mae_test": 0.35922834277153015,
    "mse_test": 0.2010621428489685,
    "seq_len": 168,
    "label_len": 96,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 3,
    "d_model": 256,
    "d_ff": 1024,
    "d_layers": 1,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация нацелена на проверку эффективности наименьшей модели (d_model=256, минимальные слои) при прогнозировании недельных зависимостей (seq_len=168), используя низкий dropout для максимального сохранения информации и повышения вычислительной эффективности."
  },
  {
    "trial": 4,
    "timestamp": "2025-11-05T12:32:18.393761",
    "mae_val": 0.2305707186460495,
    "mse_val": 0.09248217940330505,
    "mae_test": 0.30408424139022827,
    "mse_test": 0.13983410596847534,
    "seq_len": 720,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 8,
    "d_model": 768,
    "d_ff": 2048,
    "d_layers": 2,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация исследует влияние максимальной глубины кодировщика (e_layers=6) в сочетании с длинной историей (720) и высокой размерностью (768), чтобы определить, как глубокое извлечение признаков влияет на прогнозирование долгосрочных часовых рядов."
  },
  {
    "trial": 5,
    "timestamp": "2025-11-05T12:36:43.492360",
    "mae_val": 0.506584644317627,
    "mse_val": 0.3748997151851654,
    "mae_test": 0.4193989932537079,
    "mse_test": 0.2665373980998993,
    "seq_len": 336,
    "label_len": 96,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 5,
    "d_model": 512,
    "d_ff": 3072,
    "d_layers": 2,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация проверяет эффективность глубокого кодировщика (6 слоев) для извлечения признаков из умеренно длинной последовательности (336), используя стандартную размерность модели (512) и низкий дропаут для повышения вычислительной эффективности и точности среднесрочных прогнозов."
  },
  {
    "trial": 6,
    "timestamp": "2025-11-05T12:38:49.026406",
    "mae_val": 0.5854600071907043,
    "mse_val": 0.4726718068122864,
    "mae_test": 0.38278263807296753,
    "mse_test": 0.2319885939359665,
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8,
    "d_model": 768,
    "d_ff": 2048,
    "d_layers": 3,
    "dropout": 0.2,
    "hypothesis": "Конфигурация исследует, может ли максимальная ширина модели (768) и глубокий декодер (3 слоя) компенсировать использование минимальной входной последовательности (48) для высокоточного краткосрочного прогнозирования, применяя высокий дропаут для регуляризации."
  },
  {
    "trial": 7,
    "timestamp": "2025-11-05T12:42:38.503916",
    "mae_val": 0.5073596835136414,
    "mse_val": 0.3491973280906677,
    "mae_test": 0.3665720224380493,
    "mse_test": 0.1991041600704193,
    "seq_len": 336,
    "label_len": 168,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3,
    "d_model": 768,
    "d_ff": 1024,
    "d_layers": 1,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация предназначена для проверки эффективности сочетания максимальной ширины модели (d_model=768) с умеренной длиной истории (336) и большим объемом начальных токенов декодера (label_len=168), используя минимальный d_ff и d_layers для экономии ресурсов."
  },
  {
    "trial": 8,
    "timestamp": "2025-11-05T12:44:22.670994",
    "mae_val": 0.5510546565055847,
    "mse_val": 0.4634571969509125,
    "mae_test": 0.3768339157104492,
    "mse_test": 0.22062444686889648,
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 10,
    "d_model": 512,
    "d_ff": 2048,
    "d_layers": 2,
    "dropout": 0.2,
    "hypothesis": "Данный эксперимент исследует, насколько глубокое кодирование (e_layers=6) способно компенсировать использование короткой входной последовательности (96) для краткосрочного прогнозирования, применяя максимальный фактор внимания и высокий dropout для лучшей регуляризации."
  },
  {
    "trial": 9,
    "timestamp": "2025-11-05T12:48:33.515541",
    "mae_val": 0.8138604164123535,
    "mse_val": 0.8323287963867188,
    "mae_test": 0.5026739835739136,
    "mse_test": 0.387821763753891,
    "seq_len": 336,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5,
    "d_model": 768,
    "d_ff": 1024,
    "d_layers": 3,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация использует глубокий кодировщик (6 слоев) и максимальную ширину модели (768) для извлечения сложных признаков из двухнедельной истории (336), а также применяет максимальную глубину декодера (3 слоя) и низкий дропаут (0.05) для достижения высокой точности при прогнозировании."
  },
  {
    "trial": 10,
    "timestamp": "2025-11-05T12:51:02.738106",
    "mae_val": 0.34891477227211,
    "mse_val": 0.19799411296844482,
    "mae_test": 0.29271039366722107,
    "mse_test": 0.12994623184204102,
    "seq_len": 720,
    "label_len": 96,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 8,
    "d_model": 256,
    "d_ff": 3072,
    "d_layers": 2,
    "dropout": 0.1,
    "hypothesis": "Данная конфигурация проверяет, насколько эффективно минимальная ширина модели (d_model=256) может обрабатывать долгосрочные зависимости (seq_len=720), используя максимальный размер FFN (3072) для увеличения нелинейной репрезентативной способности и умеренные слои кодировщика/декодера."
  },
  {
    "trial": 11,
    "timestamp": "2025-11-05T12:54:37.808140",
    "mae_val": 0.4771156311035156,
    "mse_val": 0.31979507207870483,
    "mae_test": 0.3049931526184082,
    "mse_test": 0.15293848514556885,
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 1,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация тестирует комбинацию максимальной мощности модели (d_model=768, e_layers=6) на двухнедельной последовательности (336), чтобы определить, может ли мощное извлечение признаков компенсировать минимальную длину начального токена декодера (24) и мелкий декодер (1 слой)."
  },
  {
    "trial": 12,
    "timestamp": "2025-11-05T12:56:07.727512",
    "mae_val": 0.6003932952880859,
    "mse_val": 0.49190667271614075,
    "mae_test": 0.3034087121486664,
    "mse_test": 0.14955589175224304,
    "seq_len": 168,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 10,
    "d_model": 512,
    "d_ff": 1024,
    "d_layers": 3,
    "dropout": 0.05,
    "hypothesis": "Данная настройка оценивает эффективность стандартной модели (d_model=512) для недельной истории (168), используя глубокий декодер (3 слоя) и максимальный фактор внимания (10), чтобы оптимизировать точность краткосрочного прогнозирования при сохранении вычислительной эффективности."
  },
  {
    "trial": 13,
    "timestamp": "2025-11-05T12:59:36.230311",
    "mae_val": 0.32269716262817383,
    "mse_val": 0.18109989166259766,
    "mae_test": 0.2989426851272583,
    "mse_test": 0.13668882846832275,
    "seq_len": 720,
    "label_len": 168,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 10,
    "d_model": 512,
    "d_ff": 1024,
    "d_layers": 1,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация проверяет, может ли длинная история (720) в сочетании с максимально агрессивным механизмом прореживания внимания (factor=10) и вычислительно эффективной, минимальной по глубине моделью (d_layers=1, d_ff=1024) обеспечить высокую производительность при низком дропауте."
  },
  {
    "trial": 14,
    "timestamp": "2025-11-05T13:02:01.332782",
    "mae_val": 0.7983912825584412,
    "mse_val": 0.8237991333007812,
    "mae_test": 0.45826226472854614,
    "mse_test": 0.3312264680862427,
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 3,
    "d_model": 256,
    "d_ff": 3072,
    "d_layers": 3,
    "dropout": 0.2,
    "hypothesis": "Конфигурация исследует эффективность максимальной глубины кодировщика (e_layers=6) и декодера (d_layers=3) для извлечения признаков из недельной истории (168), используя наименьший d_model (256), но компенсируя его максимальным размером FFN (3072) и высоким дропаутом для регуляризации."
  },
  {
    "trial": 15,
    "timestamp": "2025-11-05T13:07:53.994515",
    "mae_val": 0.3535580635070801,
    "mse_val": 0.19044354557991028,
    "mae_test": 0.42714494466781616,
    "mse_test": 0.2738152742385864,
    "seq_len": 720,
    "label_len": 24,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 5,
    "d_model": 512,
    "d_ff": 3072,
    "d_layers": 2,
    "dropout": 0.1,
    "hypothesis": "Мы тестируем способность модели прогнозировать на основе максимальной истории (720 часов) при минимальном количестве начальных токенов декодера (24), полагаясь на максимальный размер FFN для увеличения нелинейной репрезентативной способности."
  },
  {
    "trial": 16,
    "timestamp": "2025-11-05T13:11:55.517226",
    "mae_val": 0.765972912311554,
    "mse_val": 0.749839186668396,
    "mae_test": 0.4439842700958252,
    "mse_test": 0.29668503999710083,
    "seq_len": 168,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3,
    "d_model": 768,
    "d_ff": 2048,
    "d_layers": 3,
    "dropout": 0.05,
    "hypothesis": "Данная конфигурация использует максимальную ширину (d_model=768) и глубокий декодер (3 слоя) для извлечения сложных еженедельных паттернов (168 часов), с низким дропаутом для максимизации информационного потока в глубокой структуре."
  },
  {
    "trial": 17,
    "timestamp": "2025-11-05T13:20:14.197522",
    "mae_val": 0.5779827833175659,
    "mse_val": 0.4328003525733948,
    "mae_test": 0.4151192009449005,
    "mse_test": 0.26129037141799927,
    "seq_len": 336,
    "label_len": 168,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 8,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 3,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация исследует максимальную репрезентативную мощность (d_model=768, d_ff=3072, глубокий декодер) при использовании умеренно длинной истории (336) и большого объема начальных токенов (168), чтобы оптимизировать среднесрочное прогнозирование для данных ETTh."
  },
  {
    "trial": 18,
    "timestamp": "2025-11-05T13:20:38.403719",
    "mae_val": 0.5689584016799927,
    "mse_val": 0.4018804132938385,
    "mae_test": 0.3674377202987671,
    "mse_test": 0.21009930968284607,
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 3,
    "d_model": 256,
    "d_ff": 1024,
    "d_layers": 1,
    "dropout": 0.2,
    "hypothesis": "Конфигурация нацелена на тестирование предела вычислительной эффективности, используя минимальные архитектурные параметры (d_model=256, e_layers=2, d_layers=1) и короткую историю (96), компенсируя простоту модели высоким дропаутом для лучшей регуляризации."
  },
  {
    "trial": 19,
    "timestamp": "2025-11-05T13:24:52.039612",
    "mae_val": 0.34089481830596924,
    "mse_val": 0.19111795723438263,
    "mae_test": 0.4180106818675995,
    "mse_test": 0.2561207115650177,
    "seq_len": 720,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 10,
    "d_model": 256,
    "d_ff": 2048,
    "d_layers": 3,
    "dropout": 0.1,
    "hypothesis": "Исследуем способность минимальной ширины модели (d_model=256) эффективно обрабатывать длинную последовательность (720) за счет максимальной глубины кодировщика/декодера (6/3) и агрессивного механизма прореживания внимания (factor=10)."
  },
  {
    "trial": 20,
    "timestamp": "2025-11-05T13:25:53.436174",
    "mae_val": 0.5088059306144714,
    "mse_val": 0.3940638601779938,
    "mae_test": 0.2788394093513489,
    "mse_test": 0.13201698660850525,
    "seq_len": 96,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 5,
    "d_model": 768,
    "d_ff": 1024,
    "d_layers": 2,
    "dropout": 0.05,
    "hypothesis": "Проверяем эффективность широкой, но мелкой архитектуры (d_model=768, e_layers=2) с максимальным количеством голов (n_heads=16) для быстрого и точного краткосрочного прогнозирования (seq_len=96), используя минимальный dropout для сохранения детализированных признаков."
  },
  {
    "trial": 21,
    "timestamp": "2025-11-05T13:29:22.316441",
    "mae_val": 0.5624145865440369,
    "mse_val": 0.4787891209125519,
    "mae_test": 0.5104573965072632,
    "mse_test": 0.3648602366447449,
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 16,
    "factor": 5,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 3,
    "dropout": 0.1,
    "hypothesis": "Testing if maximizing the architectural capacity (6 encoder layers, 3 decoder layers, maximum d_model/d_ff) can significantly enhance feature extraction for very short input sequences (48 hours), using a moderate dropout for stability."
  },
  {
    "trial": 22,
    "timestamp": "2025-11-05T13:31:51.942392",
    "mae_val": 0.24580080807209015,
    "mse_val": 0.1006067544221878,
    "mae_test": 0.3452536463737488,
    "mse_test": 0.1830345094203949,
    "seq_len": 720,
    "label_len": 336,
    "e_layers": 4,
    "n_heads": 8,
    "factor": 10,
    "d_model": 256,
    "d_ff": 1024,
    "d_layers": 1,
    "dropout": 0.2,
    "hypothesis": "Эта конфигурация исследует, может ли агрессивный фактор внимания (10) в сочетании с максимальной длиной начальных токенов (336) позволить вычислительно минимальной модели (d_model=256, d_layers=1) эффективно справляться с долгосрочным прогнозированием (720 часов), используя высокий дропаут для регуляризации."
  },
  {
    "trial": 23,
    "timestamp": "2025-11-05T13:36:47.827581",
    "mae_val": 0.5244393348693848,
    "mse_val": 0.37385043501853943,
    "mae_test": 0.4422111511230469,
    "mse_test": 0.2886697053909302,
    "seq_len": 336,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 10,
    "d_model": 768,
    "d_ff": 2048,
    "d_layers": 2,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация исследует, как максимальная ширина модели (d_model=768) и максимальный фактор прореживания (factor=10) взаимодействуют при обработке умеренной истории (336 часов), используя низкий дропаут для сохранения деталей."
  },
  {
    "trial": 24,
    "timestamp": "2025-11-05T13:37:21.888475",
    "mae_val": 0.4388482868671417,
    "mse_val": 0.26983770728111267,
    "mae_test": 0.2819945514202118,
    "mse_test": 0.12614810466766357,
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 3,
    "n_heads": 8,
    "factor": 3,
    "d_model": 256,
    "d_ff": 3072,
    "d_layers": 1,
    "dropout": 0.2,
    "hypothesis": "Эта конфигурация проверяет эффективность минимальной ширины модели (d_model=256) для краткосрочного прогнозирования (48 часов), компенсируя ее максимальным размером FFN и высоким дропаутом для сильной регуляризации."
  },
  {
    "trial": 25,
    "timestamp": "2025-11-05T13:41:29.397127",
    "mae_val": 0.38396748900413513,
    "mse_val": 0.23278865218162537,
    "mae_test": 0.36052122712135315,
    "mse_test": 0.1992928832769394,
    "seq_len": 720,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 3,
    "d_model": 512,
    "d_ff": 1024,
    "d_layers": 3,
    "dropout": 0.2,
    "hypothesis": "Эта конфигурация исследует, может ли умеренная ширина модели (d_model=512) эффективно обрабатывать максимальную длину последовательности (720) при сочетании минимального фактора внимания (factor=3) и максимальной глубины декодера (d_layers=3) для тщательного изучения долгосрочных зависимостей."
  },
  {
    "trial": 26,
    "timestamp": "2025-11-05T13:43:58.672210",
    "mae_val": 0.37541934847831726,
    "mse_val": 0.2208912968635559,
    "mae_test": 0.2997906804084778,
    "mse_test": 0.1438068300485611,
    "seq_len": 336,
    "label_len": 24,
    "e_layers": 2,
    "n_heads": 8,
    "factor": 8,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 1,
    "dropout": 0.1,
    "hypothesis": "Данная конфигурация проверяет, насколько эффективно максимальная ширина модели (d_model=768, d_ff=3072) в сочетании с минимальной глубиной кодировщика (e_layers=2) может извлекать признаки из двухнедельной истории (336), используя минимальный декодер для быстрого прогнозирования."
  },
  {
    "trial": 27,
    "timestamp": "2025-11-05T13:51:53.949851",
    "mae_val": 0.34789904952049255,
    "mse_val": 0.1978115290403366,
    "mae_test": 0.29123130440711975,
    "mse_test": 0.13220354914665222,
    "seq_len": 720,
    "label_len": 168,
    "e_layers": 2,
    "n_heads": 16,
    "factor": 5,
    "d_model": 768,
    "d_ff": 3072,
    "d_layers": 2,
    "dropout": 0.1,
    "hypothesis": "Эта конфигурация проверяет, может ли максимальная ширина модели и длинная история (720 часов) в сочетании с большим количеством начальных токенов декодера (168) компенсировать минимальную глубину кодировщика (e_layers=2) для высокоточного долгосрочного прогнозирования."
  },
  {
    "trial": 28,
    "timestamp": "2025-11-05T13:54:41.510146",
    "mae_val": 0.7519358396530151,
    "mse_val": 0.7019641399383545,
    "mae_test": 0.4429584741592407,
    "mse_test": 0.30197784304618835,
    "seq_len": 168,
    "label_len": 48,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3,
    "d_model": 512,
    "d_ff": 2048,
    "d_layers": 3,
    "dropout": 0.05,
    "hypothesis": "Данная конфигурация исследует, может ли максимальная глубина кодировщика и декодера (6/3) в сочетании с минимальным дропаутом и менее агрессивным прореживанием внимания (factor=3) эффективно извлекать сложные недельные паттерны, используя стандартную ширину модели (d_model=512)."
  },
  {
    "trial": 29,
    "timestamp": "2025-11-05T13:58:40.300490",
    "mae_val": 0.6302042007446289,
    "mse_val": 0.49468499422073364,
    "mae_test": 0.4145318567752838,
    "mse_test": 0.2560156583786011,
    "seq_len": 336,
    "label_len": 96,
    "e_layers": 4,
    "n_heads": 16,
    "factor": 10,
    "d_model": 512,
    "d_ff": 2048,
    "d_layers": 2,
    "dropout": 0.05,
    "hypothesis": "Эта конфигурация тестирует эффективность максимальной агрессивности прореживания (factor=10) в сочетании с умеренной историей (336) и минимальным дропаутом (0.05), используя стандартную ширину модели (512) для эффективного захвата двухнедельных зависимостей."
  },
  {
    "trial": 30,
    "timestamp": "2025-11-05T14:00:16.248463",
    "mae_val": 0.5157919526100159,
    "mse_val": 0.41093313694000244,
    "mae_test": 0.44721320271492004,
    "mse_test": 0.2929152846336365,
    "seq_len": 48,
    "label_len": 24,
    "e_layers": 6,
    "n_heads": 8,
    "factor": 3,
    "d_model": 256,
    "d_ff": 1024,
    "d_layers": 3,
    "dropout": 0.1,
    "hypothesis": "Мы исследуем, может ли максимальная глубина кодировщика (6) и декодера (3) компенсировать минимальную ширину модели (256) и кратчайшую историю (48), используя минимальный фактор прореживания для тщательного анализа небольшого объема данных."
  }
]